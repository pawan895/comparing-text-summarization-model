{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2089f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "!pip install torch\n",
    "!pip install sentencepiece \n",
    "!pip install --upgrade transformers\n",
    "!pip install rouge \n",
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b1d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bpawa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration \n",
    "import torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740f9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PegasusForConditionalGeneration \n",
    "model_name = 'google/pegasus-large' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28bfaa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bpawa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning, a subset of AI, enables systems to learn and improve from experience without explicit programming. OpenAI's GPT-3, for instance, is a powerful NLP model that has demonstrated remarkable language understanding and generation capabilities. As we embrace these advancements, it is crucial to address ethical considerations and work towards responsible AI development.\n"
     ]
    }
   ],
   "source": [
    "# Load the Pegasus tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "with open('./content/justafile.txt', 'r') as f: \n",
    " arxiv_paper = f.read() \n",
    "input_chunks = [arxiv_paper[i:i+512] for i in range(0, len(arxiv_paper), 512)] \n",
    "summaries = []\n",
    "\n",
    "for chunk in input_chunks: \n",
    " input_ids = tokenizer.encode(chunk, return_tensors='pt') \n",
    " output = model.generate(input_ids, max_length=100, num_beams=5, length_penalty=0.8) \n",
    " summary = tokenizer.decode(output[0], skip_special_tokens=True) \n",
    " summaries.append(summary) \n",
    "summary = ' '.join(summaries) \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982d0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summary=\"\"\"Artificial intelligence (AI) is transforming industries by enhancing efficiency and enabling data-driven decisions. Machine learning, a subset of AI, facilitates learning from experience without explicit programming. Natural language processing (NLP) is a key application, allowing computers to understand and generate human-like text. OpenAI's GPT-3 exemplifies powerful NLP capabilities. Despite advancements, ethical concerns like bias, data privacy, and job displacement persist. Striking a balance between progress and ethical responsibility is crucial for the positive impact of AI on society.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2830be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"rouge-1\": {\n",
      "            \"r\": 0.34285714285714286,\n",
      "            \"p\": 0.5,\n",
      "            \"f\": 0.4067796561907498\n",
      "        },\n",
      "        \"rouge-2\": {\n",
      "            \"r\": 0.15384615384615385,\n",
      "            \"p\": 0.23076923076923078,\n",
      "            \"f\": 0.18461537981538473\n",
      "        },\n",
      "        \"rouge-l\": {\n",
      "            \"r\": 0.3142857142857143,\n",
      "            \"p\": 0.4583333333333333,\n",
      "            \"f\": 0.37288135110600407\n",
      "        }\n",
      "    }\n",
      "]\n",
      "Number of sentences: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bpawa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "import json\n",
    "rouge = Rouge() \n",
    "scores = rouge.get_scores(summary, reference_summary) \n",
    "print(json.dumps(scores, indent=4)) \n",
    "\n",
    "import nltk \n",
    "# download punkt tokenizer \n",
    "nltk.download('punkt') \n",
    "sentences = nltk.sent_tokenize(summary) \n",
    "num_sentences = len(sentences) \n",
    "print(\"Number of sentences:\", num_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ad97af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = 'results'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the ROUGE scores to a text file in the new directory\n",
    "file_path = os.path.join(directory, 'pagus_rouge_scores.txt')\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(json.dumps(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504fed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
